type: "orchestration"
version: "1.0"
pipeline:
  components:
    Start:
      type: "start"
      transitions:
        unconditional:
        - "TABLE METADATA"
        - "Database Query"
      parameters:
        componentName: "Start"
    Database Query:
      type: "database-query"
      transitions:
        success:
        - "Table Iterator 2"
      skipped: true
      parameters:
        componentName: "Database Query"
        basicAdvancedMode: "Advanced"
        databaseType: "Snowflake"
        connectionUrl: "jdbc:snowflake://nzefhhx-lg42617.snowflakecomputing.com"
        username: "black045"
        password: "SNOWFLAKE-BLACK-PWD"
        connectionOptions:
        sqlQuery: "select * from pc_matillionloader_db.incremental_load.\"customers\"\
          \ ;"
        fetchSize:
        type: "Standard"
        primaryKeys:
        warehouse1: "[Environment Default]"
        database: "[Environment Default]"
        schema: "INCREMENTAL_LOAD"
        targetTable: "customers"
        stage1: "[Custom]"
        stagePlatform: "Snowflake Managed"
        loadOptions:
        sshTunnel:
      postProcessing:
        updateScalarVariables:
    TABLE METADATA:
      type: "database-query"
      transitions:
        success:
        - "Query Result To Grid"
      parameters:
        componentName: "TABLE METADATA"
        basicAdvancedMode: "Advanced"
        databaseType: "Snowflake"
        connectionUrl: "jdbc:snowflake://nzefhhx-lg42617.snowflakecomputing.com"
        username: "black045"
        password: "SNOWFLAKE-BLACK-PWD"
        connectionOptions:
        sqlQuery: "select * from snowflake_sample_data.information_schema.tables where\
          \ table_schema = 'TPCH_SF1'"
        fetchSize:
        type: "Standard"
        primaryKeys:
        warehouse1: "[Environment Default]"
        database: "[Environment Default]"
        schema: "INCREMENTAL_LOAD"
        targetTable: "customers"
        stage1: "[Custom]"
        stagePlatform: "Snowflake Managed"
        loadOptions:
        sshTunnel:
      postProcessing:
        updateScalarVariables:
    Query Result To Grid:
      type: "query-to-grid"
      transitions:
        success:
        - "Table Iterator RO"
      parameters:
        componentName: "Query Result To Grid"
        mode: "Advanced"
        gridVariable: "GRID_VAR"
        gridVariableMapping:
        - - "TABLE_NAME"
          - "TABLE_NAME"
        query: "select * from snowflake_sample_data.information_schema.tables where\
          \ table_schema = 'TPCH_SF1'"
      postProcessing:
        updateScalarVariables:
    Print Variables:
      type: "print-variables"
      parameters:
        componentName: "Print Variables"
        variablesToPrint:
        - - "TABLE_NAME"
        prefixText:
        includeVariableName: "Yes"
      postProcessing:
        updateScalarVariables:
    Table Iterator 2:
      type: "table-iterator"
      transitions:
        success:
        - "And"
      iterationTarget: "Print Variables"
      parameters:
        componentName: "Table Iterator 2"
        mode: "Advanced"
        query: "select * from snowflake_sample_data.information_schema.tables where\
          \ table_schema = 'TPCH_SF1'"
        concurrency: "Sequential"
        columnMapping1:
        - - "TABLE_CATALOG"
          - "TABLE_CATALOG"
        - - "TABLE_SCHEMA"
          - "TABLE_SCHEMA"
        - - "TABLE_NAME"
          - "TABLE_NAME"
        breakOnFailure: "No"
      postProcessing:
        updateScalarVariables:
    Run Orchestration:
      type: "run-orchestration"
      parameters:
        componentName: "Run Orchestration"
        orchestrationJob: "Nested Check Orchestration.orch.yaml"
        setScalarVariables:
        - - "TABLE_NAME"
          - "${TABLE_NAME}"
        - - "TABLE_CATALOG"
          - "${TABLE_CATALOG}"
        - - "TABLE_SCHEMA"
          - "${TABLE_SCHEMA}"
        setGridVariables:
      postProcessing:
        updateScalarVariables:
    Table Iterator RO:
      type: "table-iterator"
      transitions:
        success:
        - "And"
      iterationTarget: "Run Orchestration"
      skipped: false
      parameters:
        componentName: "Table Iterator RO"
        mode: "Advanced"
        query: "/*select * from snowflake_sample_data.information_schema.tables where\
          \ table_schema = 'TPCH_SF1'*/\r\n\r\nselect * from PC_MATILLIONLOADER_DB.information_schema.tables\
          \ where table_schema = 'MOVIES_SCHEMA'"
        concurrency: "Sequential"
        columnMapping1:
        - - "TABLE_CATALOG"
          - "TABLE_CATALOG"
        - - "TABLE_SCHEMA"
          - "TABLE_SCHEMA"
        - - "TABLE_NAME"
          - "TABLE_NAME"
        breakOnFailure: "No"
      postProcessing:
        updateScalarVariables:
    SQL Script:
      type: "sql-executor"
      parameters:
        componentName: "SQL Script"
        scriptLocation: "Component"
        declareSqlVariables: "Include selected"
        variablesToInclude:
        sqlScript: "/*\r\nCREATE OR REPLACE TABLE config.matillion_audit_log (\r\n\
          \  environment_name VARCHAR,\r\n  project_id VARCHAR,\r\n  root_pipeline_execution_id\
          \ VARCHAR,\r\n  pipeline_full_name VARCHAR,\r\n  pipeline_execution_id VARCHAR,\r\
          \n  component_name VARCHAR,\r\n  component_status VARCHAR,\r\n  component_task_id\
          \ VARCHAR,\r\n  component_message VARCHAR,\r\n  component_row_count VARCHAR,\r\
          \n  component_started_at VARCHAR,\r\n  component_finished_at VARCHAR,\r\n\
          \  component_duration_ms VARCHAR,\r\n  artifact_version_name VARCHAR,\r\n\
          \  audit_TS TIMESTAMP,\r\n  MAX_TS VARCHAR\r\n);\r\n*/\r\n\r\nINSERT INTO\
          \ config.matillion_audit_log (\r\n  environment_name,\r\n  project_id,\r\
          \n  root_pipeline_execution_id,\r\n  pipeline_full_name,\r\n  pipeline_execution_id,\r\
          \n  component_name,\r\n  component_status,\r\n  component_task_id,\r\n \
          \ component_message,\r\n  component_row_count,\r\n  component_started_at,\r\
          \n  component_finished_at,\r\n  component_duration_ms,\r\n  artifact_version_name,\r\
          \n  audit_TS,\r\n  MAX_TS VARCHAR\r\n)\r\nSELECT \r\n  $$${sysvar.environment.name}$$,\r\
          \n  $$${sysvar.project.id}$$,\r\n  $$${sysvar.rootPipeline.executionId}$$,\r\
          \n  $$${sysvar.thisPipeline.fullName}$$,\r\n  $$${sysvar.thisPipeline.executionId}$$,\r\
          \n  $$${COMPONENT_NAME}$$,\r\n  $$${COMPONENT_STATUS}$$,\r\n  $$${sysvar.thisComponent.taskId}$$,\r\
          \n  $$${COMPONENT_ERROR}$$,\r\n  $$${sysvar.thisComponent.rowCount}$$,\r\
          \n  $$${sysvar.thisComponent.startedAt}$$,\r\n  $$${sysvar.thisComponent.mainTaskFinishedAt}$$,\r\
          \n  $$${sysvar.thisComponent.mainTaskDurationMs}$$,\r\n  $$${sysvar.artifact.versionName}$$,\r\
          \n  CURRENT_TIMESTAMP as audit_TS,\r\n  NULL AS MAX_TS;\r\n"
      postProcessing:
        updateScalarVariables:
    And:
      type: "and"
      transitions:
        unconditional:
        - "Retry"
      parameters:
        componentName: "And"
      postProcessing:
        updateScalarVariables:
    Retry:
      type: "retry"
      iterationTarget: "SQL Script"
      skipped: true
      parameters:
        componentName: "Retry"
        numberOfRetries: "3"
        retryDelay: "Short delay"
      postProcessing:
        updateScalarVariables:
  variables:
    TABLE_CATALOG:
      metadata:
        type: "TEXT"
        description: ""
        scope: "SHARED"
        visibility: "PUBLIC"
      defaultValue: "\"\""
    TABLE_NAME:
      metadata:
        type: "TEXT"
        description: ""
        scope: "SHARED"
        visibility: "PUBLIC"
      defaultValue: "\"\""
    TABLE_SCHEMA:
      metadata:
        type: "TEXT"
        description: ""
        scope: "SHARED"
        visibility: "PUBLIC"
      defaultValue: "\"\""
    GRID_VAR:
      metadata:
        type: "GRID"
        description: ""
        scope: "SHARED"
        visibility: "PUBLIC"
        columns:
          TABLE_NAME:
            columnType: "TEXT"
      defaultValue: []
design:
  components:
    Start:
      position:
        x: -850
        "y": -110
      tempMetlId: 1
    Database Query:
      position:
        x: -520
        "y": -160
      tempMetlId: 2
    TABLE METADATA:
      position:
        x: -700
        "y": -60
      tempMetlId: 3
    Query Result To Grid:
      position:
        x: -540
        "y": -60
      tempMetlId: 6
    Print Variables:
      position:
        x: -330
        "y": -190
      tempMetlId: 9
    Table Iterator 2:
      position:
        x: -330
        "y": -190
      tempMetlId: 10
    Run Orchestration:
      position:
        x: -360
        "y": -80
      tempMetlId: 11
    Table Iterator RO:
      position:
        x: -360
        "y": -80
      tempMetlId: 12
    SQL Script:
      position:
        x: -130
        "y": -100
      tempMetlId: 13
    And:
      position:
        x: -230
        "y": -100
      tempMetlId: 14
    Retry:
      position:
        x: -130
        "y": -120
      tempMetlId: 15
  notes:
    "1":
      position:
        x: 440
        "y": -160
      size:
        height: 238
        width: 820
      theme: "white"
      content: "shall we do like this?\n\nLoad the data using Database Query and fetch\
        \ the last processed date and put it into blob storage and then access that\
        \ blob data as a external table in transformation job to do merge logic.\n\
        \n1. SCD Type - 2 Method in Datbricks blog:\nhttps://www.databricks.com/blog/2023/01/25/loading-data-warehouse-slowly-changing-dimension-type-2-using-matillion.html\n\
        \n2.JDBC Incremental Load : \nhttps://docs.matillion.com/metl/docs/2955330/\n"
